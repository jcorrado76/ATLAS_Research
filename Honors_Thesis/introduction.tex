\chapter{Introduction}
\section{The Large Hadron Collider}
The Large Hadron Collider is the most powerful particle accelerator in the world, located in CERN on the France-Swiss border.
The circumference of the LHC is 27km, and is located 100m underground. 
The maximum energy possible to accelerate the particles to in the LHC is directly dependent on the size of the LHC and the strength of the magnets used to accelerate the particles. 
In order to achieve the design energy of 7 TeV per proton, it was necessary to have a circumference of 27km, and to use some of the most powerful dipoles and radiofrequency cavities in existence. 
Inside the pipes where the protons travel, a very strong vacuum is required, and so the pressure in some parts is over $10^{-9}Pa$. 
The beams are made up of cylinder-like bunches. 
Using these bunches, the expectde number of collisiosn is $10^{34}$ per $cm^2$ per second. 
The time between bunches is about $25ns$, so in the entire circumference of the LHC, there are about $3550$ bunches.
\section{ATLAS Experiment}
\textbf{ATLAS (A Toroidal LHC ApparatuS)} is one of seven particle detector experiments constructed at the Large Hadron Collider, a particle accelerator at CERN. 
When the LHC runs at full energy and intensity, about 600 million proton-proton collisions take place every second inside the ATLAS detector. 
The amount of data collected for each event is around 1MB, which means that there is approximately:
$$10^9Hz(1Mb)=1Pb/s$$
of data produced. 
Because this is significantly larger than any practical system can handle, there are \textbf{triggers} that are designed to reject uninteresting events and keep the interesting ones. 
For ATLAS, the trigger system is deisgned to collect about 200 events epr second. 
This means that ATLAS collects about 4 petabytes of data per year. 
There are $10^{11}$ protons in a bunch. 
The proton-proton interaction cross section is approximately $100mB$.


\section{Efficiency Curves}
An efficiency curve illustrates the probability of a given test algorithm to classify an event as above or below a certain threshold as a function of some given true determination of the MET. 
So we can ask, what is the efficiency of L1 $> 30$ as a function of CELL MET. What this is means is we are taking the MET as determined by CELL to be the true MET, and we want to know how well L1 does at classifying events as having MET above or below $30$ at each value of the MET determine by CELL. 
The way one would read a plot of this efficiency is to pick a value of CELL MET ( on the x-axis ) and ask ``when CELL determined events had this MET, how often did L1 determine the MET of those same events was greater than the threshold [30 GeV]''. 
The fraction [of the total amount of events CELL determined was in that MET bin] that L1 determined was greater than the threshold would be the height of the efficiency curve at that value of CELL MET.
A perfect efficiency curve would look like a step function centered at the threshold around which one is trying to classify the MET of events. 
The fact that efficiency curves in reality do not look like step functions can be understood in terms of Type I and Type II error. 
The step function for the efficiency curve would be centered on the threshold one is asking for the efficiency about. 
The fact that the efficiency curve immediately to the left of the threshold is not zero means that there were events that CELL said had an MET lower than the threshold, but L1 said those same events were higher than the threshold. 
The fact that the efficiency curve, immediately to the right of the threshold is not one means that there were events that CELL said had a higher MET than the threshold, but L1 said those same events were lower than the threshold. 
In this case, the fraction of events L1 determined had an MET higher than the threshold, given that CELL said the MET was higher than the threshold, is less than one.
\section{Trigger System}
In particle physics, a trigger is a system that uses simple criteria to rapidly decide which events in a particle detector to keep when only a small fraction of the total can be recorded.
The trigger system is necessary because of limitations in terms of data storage capacity and rates. 
In general, the experiments typically search for ``interesting'' events (decays of rare particles) that occur at relatively low rates, so we need to have trigger systems that identify events that should be recorded for later analysis. 
The Large Hadron Collider has an event rate of approximately 1 GHz. 
The triggers are divided into levels so that each level selects the data that becomes an input for the next level, which has more time available and more information to make better decisions.
There is the \textbf{Level-1 (L1)} system, which is based on custom eletronics, and the \textbf{High Level Trigger (HLT)} system, that relies on commercial processors. 
The L1 system uses only coarsely segmented data from the calorimeter and muon detectors, while holding all the high-resolution data in pipeline memories in the electronics.
\section{Missing Transverse Momentum}

